1. To check if an anagram of input string t is a substring of s, I first store letter counts in t using Counter from collections. All anagrams of input string t have the same letter count. Checking to see if a substring of s have the same letter count as letter counts in t would find an anagram. So, I generate all consecutive substrings of s and check to see if the letter count matches in t and substrings of s. In the worst case, the algorithm rumtime efficiency is O(len(s)) if we have to loop through all consecutive substrings of s. Space effieciency is constant O(1) because we store letters' counts in a dictionary with at most 26 letters.

2. To find the longest palindromic substring in an input string a, I loop through the string and loop for even and odd palindromic substrings. To find odd palindromes, I loop over the string and check if neighboring elements are the same. If they are, I check if their neighbors are also the same, progressively increasing the length of the palindrome. To find even palindromes, I check to see if any adjacent elements are the same. Then, expand outward if they are to find the longest palindromic substring in a. The algorithm's time efficiency is O(n^2) because we loop over n elements of the input string and also search through the string for the longest substring. The space efficiency of the algorithm does not require any additional data structures, so it is constant, O(1).

3. To find the minimum spanning tree in a weighted undirected graph, I implement Prim's algorithm to traverse every node and edge at least once. I keep track of what nodes are visited, the weights and the path from one node to another. I loop over all the nodes until we visit all the vertices and edges. The weights are stored in an array and searching through the array for the edge with the minimum weight requires O (n^2) runtime, where n is the number of nodes in the graph. The algorithm requires keeping track of which nodes are known, their weights and the path to the neighbors for each node. I keep these values in three lists of size n. From the input dictionary, I make another list with nodes to loop through while updating the known list. To return a minimum spanning tree, I make a dictionary with at most n keys but on average, with less than n elements. So, space complexity is O(5*n) which can be approximated as O(n).

4. To find the least common ancestor on a BST, I compare the input node values to the root value. If the nodes are on opposite sides of the root, the least common ancestor is the root. If the nodes are on the same side of the root, I traverse the tree down, comparing the root's child value to the nodes and if the nodes are on the same or opposite sides, and so on. The algoirthm stops when the nodes are on opposite sides which means that the node they are compared to is their least common ancestor. The efficiency of the algorithm is O(n) because in the worse case, we need to search all the nodes in the tree. Because we do not make any extra data structures, the space complexity is O(1). 

5. To find the element that is m elements from the end of a singly linked list, I loop over the linked list once to find the length of the linked list. Then I traverse the linked list up to m elements from the end based on the length of the list and input value of m. The runtime efficiency of the algorithm is O(n) where n is the number of elements in the linked list. I do not use any extra data structures, so space efficiency is constant, O(1). 
